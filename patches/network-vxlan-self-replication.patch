Changes to support self replication (head end replication).

diff --git a/drivers/net/vxlan.c b/drivers/net/vxlan.c
index fc1b0d9..5c51530 100644
--- a/drivers/net/vxlan.c
+++ b/drivers/net/vxlan.c
@@ -118,7 +118,8 @@ struct vxlan_dev {
 	unsigned int	  addrcnt;
 	unsigned int	  addrmax;
 	unsigned int	  addrexceeded;
-	__u32		  service_nodes[MAX_VXLAN_SERVICE_NODE_ADDRS];
+	__u8          repl_type;
+	__u32		  repl_nodes[MAX_VXLAN_REPLICATION_NODE_ADDRS];
 
 	struct hlist_head fdb_head[FDB_HASH_SIZE];
 };
@@ -664,11 +665,11 @@ static __be32 vxlan_find_dst(struct vxlan_dev *vxlan, struct sk_buff *skb)
 		/* TBD: we should do some flow hash to spread, and also
 		 *      consider bfd status. for now just pick the first one
 		 */
-		for (i = 0; i < MAX_VXLAN_SERVICE_NODE_ADDRS; i++) {
-			if (vxlan->service_nodes[i] == 0)
+		for (i = 0; i < MAX_VXLAN_REPLICATION_NODE_ADDRS; i++) {
+			if (vxlan->repl_nodes[i] == 0)
 				break;
 			else
-				return vxlan->service_nodes[i];
+				return vxlan->repl_nodes[i];
 		}
 		return 0;
 	}
@@ -677,11 +678,11 @@ static __be32 vxlan_find_dst(struct vxlan_dev *vxlan, struct sk_buff *skb)
 	if (f)
 		return f->remote_ip;
 	else {
-		for (i = 0; i < MAX_VXLAN_SERVICE_NODE_ADDRS; i++) {
-                        if (vxlan->service_nodes[i] == 0)
+		for (i = 0; i < MAX_VXLAN_REPLICATION_NODE_ADDRS; i++) {
+                        if (vxlan->repl_nodes[i] == 0)
                                 break;
                         else
-                                return vxlan->service_nodes[i];
+                                return vxlan->repl_nodes[i];
                 }
 		return vxlan->gaddr;
 	}
@@ -722,13 +723,7 @@ static u16 vxlan_src_port(const struct vxlan_dev *vxlan, struct sk_buff *skb)
 	return (((u64) hash * range) >> 32) + vxlan->port_min;
 }
 
-/* Transmit local packets over Vxlan
- *
- * Outer IP header inherits ECN and DF from inner header.
- * Outer UDP destination is the VXLAN assigned port.
- *           source port is based on hash of flow
- */
-static netdev_tx_t vxlan_xmit(struct sk_buff *skb, struct net_device *dev)
+static netdev_tx_t vxlan_xmit_one(struct sk_buff *skb, struct net_device *dev, __be32 dst)
 {
 	struct vxlan_dev *vxlan = netdev_priv(dev);
 	struct rtable *rt;
@@ -738,13 +733,11 @@ static netdev_tx_t vxlan_xmit(struct sk_buff *skb, struct net_device *dev)
 	struct udphdr *uh;
 	struct flowi4 fl4;
 	unsigned int pkt_len = skb->len;
-	__be32 dst;
 	__u16 src_port;
 	__be16 df = 0;
 	__u8 tos, ttl;
 	int err;
 
-	dst = vxlan_find_dst(vxlan, skb);
 	if (!dst)
 		goto drop;
 
@@ -847,6 +840,80 @@ tx_free:
 	return NETDEV_TX_OK;
 }
 
+
+/* Transmit local packets over Vxlan
+ *
+ * Outer IP header inherits ECN and DF from inner header.
+ * Outer UDP destination is the VXLAN assigned port.
+ *           source port is based on hash of flow
+ */
+static netdev_tx_t vxlan_xmit(struct sk_buff *skb, struct net_device *dev)
+{
+	struct vxlan_dev *vxlan = netdev_priv(dev);
+	const struct ethhdr *eth = (struct ethhdr *) skb->data;
+	const struct vxlan_fdb *f;
+	struct sk_buff* nskb;
+	int i;
+	netdev_tx_t ret = NETDEV_TX_OK;
+
+	if (is_multicast_ether_addr(eth->h_dest)) {
+		if (vxlan->gaddr)
+			return (vxlan_xmit_one(skb, dev, vxlan->gaddr));
+
+		if (vxlan->repl_type == VXLAN_REPLICATION_SERVICE_NODE) {
+			/* no group address defined, try service nodes */
+			/* TBD: we should do some flow hash to spread, and also
+			 *      consider bfd status. for now just pick the first one
+			 */
+			return (vxlan_xmit_one(skb, dev, vxlan->repl_nodes[0]));
+		}
+		else if (vxlan->repl_type == VXLAN_REPLICATION_SELF) {
+			/* self replication so replicate packets to each of the peer nodes
+			 *  in the list
+			 */
+			for (i = 0; i < MAX_VXLAN_REPLICATION_NODE_ADDRS; i++) {
+				if (vxlan->repl_nodes[i] == 0)
+					break;
+				nskb = skb_clone(skb, GFP_ATOMIC);
+				ret = vxlan_xmit_one(nskb, dev, vxlan->repl_nodes[i]);
+			}
+			goto tx_free;
+		}
+		else
+			goto drop;
+	}
+
+	f = vxlan_find_mac(vxlan, eth->h_dest);
+	if (f)
+		return (vxlan_xmit_one(skb, dev, f->remote_ip));
+	else {
+		if (vxlan->repl_type == VXLAN_REPLICATION_SERVICE_NODE)
+			return (vxlan_xmit_one(skb, dev, vxlan->repl_nodes[0]));
+		else if (vxlan->repl_type == VXLAN_REPLICATION_SELF) {
+			/* self replication so replicate packets to each of the peer nodes
+			 *  in the list. If list is empty, send to gaddr
+			 */
+			for (i = 0; i < MAX_VXLAN_REPLICATION_NODE_ADDRS; i++) {
+			    if (vxlan->repl_nodes[i] == 0)
+					break;
+			    nskb = skb_clone(skb, GFP_ATOMIC);
+				ret = vxlan_xmit_one(nskb, dev, vxlan->repl_nodes[i]);
+			}
+			goto tx_free;
+		}
+		else {
+			/* use service node first for unknown unicast, if not xmit to gaddr */
+			return (vxlan_xmit_one(skb, dev, vxlan->gaddr));
+		}
+	}
+drop:
+	dev->stats.tx_dropped++;
+
+tx_free:
+	dev_kfree_skb(skb);
+	return ret;
+}
+
 /* Walk the forwarding table and purge stale entries */
 static void vxlan_cleanup(unsigned long arg)
 {
@@ -1069,7 +1136,8 @@ static const struct nla_policy vxlan_policy[IFLA_VXLAN_MAX + 1] = {
 	[IFLA_VXLAN_AGEING]	= { .type = NLA_U32 },
 	[IFLA_VXLAN_LIMIT]	= { .type = NLA_U32 },
 	[IFLA_VXLAN_PORT_RANGE] = { .len  = sizeof(struct ifla_vxlan_port_range) },
-	[IFLA_VXLAN_SERVICE_NODE] = { .len = sizeof(struct ifla_vxlan_svc_node_addrs) },
+	[IFLA_VXLAN_REPLICATION_NODE] = { .len = sizeof(struct ifla_vxlan_repl_node_addrs) },
+	[IFLA_VXLAN_REPLICATION_TYPE]	= { .type = NLA_U8 },
 };
 
 static int vxlan_validate(struct nlattr *tb[], struct nlattr *data[])
@@ -1113,10 +1181,18 @@ static int vxlan_validate(struct nlattr *tb[], struct nlattr *data[])
 			return -EINVAL;
 		}
 	}
+	if (data[IFLA_VXLAN_REPLICATION_TYPE]) {
+		u8 repl_type = nla_get_u8(data[IFLA_VXLAN_REPLICATION_TYPE]);
+		if ((repl_type != VXLAN_REPLICATION_SERVICE_NODE)
+			&& (repl_type != VXLAN_REPLICATION_SELF)) {
+			pr_debug("replication is neither based on service node nor peer node \n");
+			return -EINVAL;
+		}
+	}
 #if 0
-	if (data[IFLA_VXLAN_SERVICE_NODE]) {
-		const struct ifla_vxlan_svc_node_addrs *p
-			= nla_data(data[IFLA_VXLAN_SERVICE_NODE]);
+	if (data[IFLA_VXLAN_REPLICATION_NODE]) {
+		const struct ifla_vxlan_repl_node_addrs *p
+			= nla_data(data[IFLA_VXLAN_REPLICATION_NODE]);
 		/* TBD: check for mcast and bcast */
 	}
 #endif
@@ -1181,11 +1257,14 @@ static int vxlan_newlink(struct net *net, struct net_device *dev,
 		vxlan->port_max = ntohs(p->high);
 	}
 
-	if (data[IFLA_VXLAN_SERVICE_NODE]) {
-		const struct ifla_vxlan_svc_node_addrs *p
-			= nla_data(data[IFLA_VXLAN_SERVICE_NODE]);
-		memcpy(vxlan->service_nodes, p, sizeof(*p));
+	if (data[IFLA_VXLAN_REPLICATION_TYPE] && data[IFLA_VXLAN_REPLICATION_NODE]) {
+		const struct ifla_vxlan_repl_node_addrs *p
+                                  = nla_data(data[IFLA_VXLAN_REPLICATION_NODE]);
+		memcpy(vxlan->repl_nodes, p, sizeof(*p));
+		vxlan->repl_type = nla_get_u8(data[IFLA_VXLAN_REPLICATION_TYPE]);
 	}
+	else
+		vxlan->repl_type = VXLAN_REPLICATION_NONE;
 
 	err = register_netdevice(dev);
 	if (!err)
@@ -1218,7 +1297,8 @@ static size_t vxlan_get_size(const struct net_device *dev)
 		nla_total_size(sizeof(__u32)) +	/* IFLA_VXLAN_AGEING */
 		nla_total_size(sizeof(__u32)) +	/* IFLA_VXLAN_LIMIT */
 		nla_total_size(sizeof(struct ifla_vxlan_port_range)) +
-		nla_total_size(sizeof(struct ifla_vxlan_svc_node_addrs)) +
+		nla_total_size(sizeof(struct ifla_vxlan_repl_node_addrs)) +
+		nla_total_size(sizeof(__u8)) +	/* IFLA_VXLAN_REPLICATION_TYPE */
 		0;
 }
 
@@ -1229,7 +1309,7 @@ static int vxlan_fill_info(struct sk_buff *skb, const struct net_device *dev)
 		.low =  htons(vxlan->port_min),
 		.high = htons(vxlan->port_max),
 	};
-	struct ifla_vxlan_svc_node_addrs svcaddrs;
+	struct ifla_vxlan_repl_node_addrs repladdrs;
 
 	if (nla_put_u32(skb, IFLA_VXLAN_ID, vxlan->vni))
 		goto nla_put_failure;
@@ -1253,9 +1333,14 @@ static int vxlan_fill_info(struct sk_buff *skb, const struct net_device *dev)
 	if (nla_put(skb, IFLA_VXLAN_PORT_RANGE, sizeof(ports), &ports))
 		goto nla_put_failure;
 
-	memcpy(&svcaddrs, vxlan->service_nodes, sizeof(svcaddrs));
-	if (nla_put(skb, IFLA_VXLAN_SERVICE_NODE, sizeof(svcaddrs), &svcaddrs))
-		goto nla_put_failure;
+	if ((vxlan->repl_type != VXLAN_REPLICATION_NONE) && vxlan->repl_nodes[0]) {
+		if (nla_put_u8(skb, IFLA_VXLAN_REPLICATION_TYPE, vxlan->repl_type))
+			goto nla_put_failure;
+
+		memcpy(&repladdrs, vxlan->repl_nodes, sizeof(repladdrs));
+		if (nla_put(skb, IFLA_VXLAN_REPLICATION_NODE, sizeof(repladdrs), &repladdrs))
+			goto nla_put_failure;
+	}
 
 	return 0;
 
@@ -1263,6 +1348,64 @@ nla_put_failure:
 	return -EMSGSIZE;
 }
 
+static int vxlan_changelink(struct net_device *dev,
+                            struct nlattr *tb[], struct nlattr *data[])
+{
+	struct vxlan_dev *vxlan = netdev_priv(dev);
+
+	if (data[IFLA_VXLAN_ID] || data[IFLA_VXLAN_LINK]) {
+		pr_err("cannot change VNI or phys dev \n");
+		return -EINVAL;
+	}
+
+	if (data[IFLA_VXLAN_GROUP])
+		vxlan->gaddr = nla_get_be32(data[IFLA_VXLAN_GROUP]);
+
+	if (data[IFLA_VXLAN_LOCAL])
+		vxlan->saddr = nla_get_be32(data[IFLA_VXLAN_LOCAL]);
+
+	if (data[IFLA_VXLAN_TOS])
+		vxlan->tos = nla_get_u8(data[IFLA_VXLAN_TOS]);
+
+	if (data[IFLA_VXLAN_LEARNING]) {
+		if (nla_get_u8(data[IFLA_VXLAN_LEARNING]))
+			vxlan->learn = true;
+		else
+			vxlan->learn = false;
+	}
+
+	if (data[IFLA_VXLAN_AGEING])
+		vxlan->age_interval = nla_get_u32(data[IFLA_VXLAN_AGEING]);
+
+	if (data[IFLA_VXLAN_LIMIT])
+		vxlan->addrmax = nla_get_u32(data[IFLA_VXLAN_LIMIT]);
+
+	if (data[IFLA_VXLAN_PORT_RANGE]) {
+		const struct ifla_vxlan_port_range *p
+			= nla_data(data[IFLA_VXLAN_PORT_RANGE]);
+		vxlan->port_min = ntohs(p->low);
+		vxlan->port_max = ntohs(p->high);
+	}
+
+	/* semantics of peernode/svcnode missing in "ip link set" command is to remove
+	 * addresses if they have been configured before
+	 */
+	if (data[IFLA_VXLAN_REPLICATION_TYPE] && data[IFLA_VXLAN_REPLICATION_NODE]) {
+		const struct ifla_vxlan_repl_node_addrs *p
+                                  = nla_data(data[IFLA_VXLAN_REPLICATION_NODE]);
+		memcpy(vxlan->repl_nodes, p, sizeof(*p));
+		vxlan->repl_type = nla_get_u8(data[IFLA_VXLAN_REPLICATION_TYPE]);
+	}
+	else {
+		memset(vxlan->repl_nodes, 0, sizeof(struct ifla_vxlan_repl_node_addrs));
+		vxlan->repl_type = VXLAN_REPLICATION_NONE;
+	}
+
+	/* call notifier chains and send link msg */
+	netdev_state_change(dev);
+	return 0;
+}
+
 static struct rtnl_link_ops vxlan_link_ops __read_mostly = {
 	.kind		= "vxlan",
 	.maxtype	= IFLA_VXLAN_MAX,
@@ -1271,6 +1414,7 @@ static struct rtnl_link_ops vxlan_link_ops __read_mostly = {
 	.setup		= vxlan_setup,
 	.validate	= vxlan_validate,
 	.newlink	= vxlan_newlink,
+	.changelink	= vxlan_changelink,
 	.dellink	= vxlan_dellink,
 	.get_size	= vxlan_get_size,
 	.fill_info	= vxlan_fill_info,
diff --git a/include/linux/if_link.h b/include/linux/if_link.h
index 42a7c70..7097794 100644
--- a/include/linux/if_link.h
+++ b/include/linux/if_link.h
@@ -301,7 +301,8 @@ enum {
 	IFLA_VXLAN_AGEING,
 	IFLA_VXLAN_LIMIT,
 	IFLA_VXLAN_PORT_RANGE,
-	IFLA_VXLAN_SERVICE_NODE,
+	IFLA_VXLAN_REPLICATION_NODE = 253,
+	IFLA_VXLAN_REPLICATION_TYPE,
 	__IFLA_VXLAN_MAX
 };
 #define IFLA_VXLAN_MAX	(__IFLA_VXLAN_MAX - 1)
@@ -311,9 +312,15 @@ struct ifla_vxlan_port_range {
         __be16  high;
 };
 
-#define MAX_VXLAN_SERVICE_NODE_ADDRS 16
-struct ifla_vxlan_svc_node_addrs {
-        __u32   addrs[MAX_VXLAN_SERVICE_NODE_ADDRS];
+#define MAX_VXLAN_REPLICATION_NODE_ADDRS 64
+struct ifla_vxlan_repl_node_addrs {
+        __u32   addrs[MAX_VXLAN_REPLICATION_NODE_ADDRS];
+};
+
+enum {
+       VXLAN_REPLICATION_NONE = 0,
+       VXLAN_REPLICATION_SERVICE_NODE, /* service node based replication */
+       VXLAN_REPLICATION_SELF,         /* self or head-end replication */
 };
 
 /* SR-IOV virtual function management section */
